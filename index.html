<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Snoop Tech - ZeroX Interface</title>
    <style>
        body { margin: 0; padding: 0; background: black; overflow: hidden; color: #00f2ff; font-family: 'Courier New', monospace; }
        #ui-layer { position: fixed; top: 20px; left: 20px; font-size: 10px; letter-spacing: 2px; z-index: 10; }
        
        .btn-container { position: fixed; bottom: 30px; left: 50%; transform: translateX(-50%); display: flex; gap: 20px; z-index: 20; }
        
        button { 
            padding: 15px 25px; background: rgba(0, 242, 255, 0.1); color: #00f2ff; 
            border: 1px solid #00f2ff; cursor: pointer; font-weight: bold; text-transform: uppercase;
            transition: 0.3s;
        }
        button:hover { background: #00f2ff; color: black; box-shadow: 0 0 20px #00f2ff; }
        
        #status-zero { position: fixed; top: 50px; left: 20px; font-size: 12px; color: white; }
        #yt-player { position: absolute; visibility: hidden; pointer-events: none; } /* Player Invisível */
    </style>
</head>
<body>

<div id="ui-layer">SNOOP TECH // ZEROX_OS_v3.1</div>
<div id="status-zero">AGUARDANDO COMANDO...</div>

<div class="btn-container">
    <button id="startBtn" onclick="initExperience()">ATIVAR INTERFACE</button>
    <button id="voiceBtn" onclick="toggleVoice()" style="display:none;">FALAR COM ZEROX</button>
</div>

<video id="webcam" style="display:none;" autoplay playsinline></video>
<div id="yt-player"></div>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
<script src="https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.min.js"></script>
<script src="https://www.youtube.com/iframe_api"></script>

<script>
    // --- VARIÁVEIS DO ZEROX ---
    let recognition;
    let synth = window.speechSynthesis;
    let player; // YouTube Player

    // --- CONFIGURAÇÃO THREE.JS (Gesto e Globo) ---
    const scene = new THREE.Scene();
    const camera3D = new THREE.PerspectiveCamera(75, window.innerWidth/window.innerHeight, 0.1, 1000);
    const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
    renderer.setSize(window.innerWidth, window.innerHeight);
    document.body.appendChild(renderer.domElement);

    // Globo e Mão (Mantendo seu efeito nítido)
    const particleCount = 4000;
    const geo = new THREE.BufferGeometry();
    const pos = new Float32Array(particleCount * 3);
    const origin = new Float32Array(particleCount * 3);
    for(let i=0; i<particleCount; i++){
        const r = 1.5; const t = 2*Math.PI*Math.random(); const p = Math.acos(2*Math.random()-1);
        pos[i*3] = r*Math.sin(p)*Math.cos(t); pos[i*3+1] = r*Math.sin(p)*Math.sin(t); pos[i*3+2] = r*Math.cos(p);
        origin[i*3]=pos[i*3]; origin[i*3+1]=pos[i*3+1]; origin[i*3+2]=pos[i*3+2];
    }
    geo.setAttribute('position', new THREE.BufferAttribute(pos, 3));
    const globe = new THREE.Points(geo, new THREE.PointsMaterial({color: 0x00f2ff, size: 0.015}));
    scene.add(globe);

    const handGroup = new THREE.Group(); scene.add(handGroup);
    const joints = []; 
    for(let i=0; i<21; i++){
        const m = new THREE.Mesh(new THREE.IcosahedronGeometry(0.03,0), new THREE.MeshBasicMaterial({color: 0x00f2ff}));
        joints.push(m); handGroup.add(m);
    }
    const linesGroup = new THREE.Group(); handGroup.add(linesGroup);
    const lineMat = new THREE.LineBasicMaterial({color: 0x00aaff});
    const HAND_CONN = [[0,1],[1,2],[2,3],[3,4],[0,5],[5,6],[6,7],[7,8],[5,9],[9,10],[10,11],[11,12],[9,13],[13,14],[14,15],[15,16],[13,17],[17,18],[18,19],[19,20],[0,17]];
    camera3D.position.z = 5;

    // --- FUNÇÕES DE VOZ (ZEROX) ---
    function falar(texto) {
        const utter = new SpeechSynthesisUtterance(texto);
        utter.pitch = 0.8; utter.rate = 1.1; // Voz mais "robô"
        synth.speak(utter);
        document.getElementById('status-zero').innerText = "ZEROX: " + texto;
    }

    function initVoice() {
        const Speech = window.SpeechRecognition || window.webkitSpeechRecognition;
        recognition = new Speech();
        recognition.lang = 'pt-BR';
        
        recognition.onresult = (event) => {
            const comando = event.results[0][0].transcript.toLowerCase();
            processarComando(comando);
        };
    }

    function processarComando(cmd) {
        if (cmd.includes("horas")) {
            const agora = new Date();
            falar("Agora são exatamente " + agora.getHours() + " horas e " + agora.getMinutes() + " minutos.");
        } 
        else if (cmd.includes("tocar") || cmd.includes("música")) {
            const busca = cmd.replace("tocar", "").replace("música", "").trim();
            falar("Iniciando áudio de " + busca + ". Este áudio pode conter anúncios.");
            // Aqui simulamos o play (num sistema real usaríamos a busca da API do YouTube)
            // Para este exemplo, ele daria play no player oculto:
            player.loadVideoById('dQw4w9WgXcQ'); // Exemplo ID
            player.playVideo();
        } 
        else {
            falar("Não encontrei " + cmd + " no meu banco de dados, mas estou aprendendo.");
        }
    }

    function toggleVoice() {
        recognition.start();
        document.getElementById('status-zero').innerText = "ESCUTANDO...";
    }

    // --- INTEGRAÇÃO ---
    function onYouTubeIframeAPIReady() {
        player = new YT.Player('yt-player', { height: '0', width: '0', videoId: '' });
    }

    function initExperience() {
        document.getElementById('startBtn').style.display = 'none';
        document.getElementById('voiceBtn').style.display = 'block';
        
        initVoice();
        falar("Olá, sou Zerox. Em que posso te ajudar hoje?");

        const hands = new Hands({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
        hands.setOptions({maxNumHands: 1, minDetectionConfidence: 0.7});
        hands.onResults(res => {
            while(linesGroup.children.length>0) linesGroup.remove(linesGroup.children[0]);
            if(res.multiHandLandmarks && res.multiHandLandmarks[0]){
                const pts = res.multiHandLandmarks[0];
                pts.forEach((p,i) => {
                    joints[i].position.lerp(new THREE.Vector3(-(p.x-0.5)*7, -(p.y-0.5)*5, -p.z*4), 0.7);
                });
                HAND_CONN.forEach(c => {
                    const l = new THREE.BufferGeometry().setFromPoints([joints[c[0]].position, joints[c[1]].position]);
                    linesGroup.add(new THREE.Line(l, lineMat));
                });
            }
        });
        const cam = new Camera(document.getElementById('webcam'), {
            onFrame: async () => { await hands.send({image: document.getElementById('webcam')}); },
            width: 1280, height: 720
        });
        cam.start();
    }

    function animate() {
        requestAnimationFrame(animate);
        globe.rotation.y += 0.002;
        renderer.render(scene, camera3D);
    }
    animate();
</script>

</body>
</html>



